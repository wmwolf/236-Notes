\documentclass[10pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Package Inclusion and Document Formatting %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage
{geometry,amsmath,amsthm,mathrsfs,amssymb,graphicx,bm,hyperref,url,pdfsync,
fancyhdr}
\pagestyle{fancy}
\numberwithin{equation}{section}
%%%%%%%%%%%%%%%%%%%
% Custom Commands %
%%%%%%%%%%%%%%%%%%%
\newcommand{\n}{\noindent}
\newcommand{\norm}[1]{\left\lvert#1\right\rvert}
\newcommand{\avg}[1]{\left\langle#1\right\rangle}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\figref}[1]{Figure \ref{#1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title Page Information %
%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Notes for PHYS 236: Cosmology}
\author{Bill Wolf}
\date{\today}

\begin{document}

\vfill\maketitle\vfill \newpage

\tableofcontents \newpage

%%%%%%%%%%%%%%%%%%%%%%
% January 9, 2013 %
%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction} % (fold)
\label{sec:introduction}
	\emph{Monday, January 9, 2013}\\
	
	\n Cosmology is essentially the study of the origin and evolution of the universe. The cosmologist attempts to discover if and how the universe is evolving, when it formed, how old/big it is, etc. Understanding the dynamics and geometry of the universe is essential for a complete picture of universal evolution. To date, we have a pretty convincing model, the Big Bang Theory (BBT), which explains a vast amount of observations, but questions remain. In addition, almost none of the predictions by the BBT can be measured in a laboratory, so we are forced to rely on observations.\\
	
	\n The basic idea of the BBT is that the universe began as a very hot place and has been expanding ever since. A period of extremely rapid expansion, called the inflationary period, caused small perturbations in the density of the universe to become macroscopic artifacts. The very much cooled and expanded universe is what we observe today, but in between, many interesting things must have happened, including the nucleosynthesis of primordial elements, ionization, and various changes to the rate of cosmic expansion.
	
	\subsection{The Long View} % (fold)
	\label{sub:the_long_view}
	
	Some classic examples of observations supported by the big bang theory include
	\begin{itemize}
		\item \textbf{Olbers' Paradox}: the universe, if infinite, should be infinitely bright, and yet we observe darkness
		\item \textbf{Hubble's Law}: far away galaxies are moving away from us at a rate proportional to their distance from us
		\item \textbf{The Cosmic microwave background (CMB)}: A nearly uniform background radiation at around 2.7 K as a perfect black body
		\item \textbf{He abundance in stars}: stars have nearly uniformly 28\% He when first born
	\end{itemize}
	However the BBT is not without flaws. Some difficulties remain, including
	\begin{itemize}
		\item \textbf{The Horizon Problem}: Points in the universe that are causally disconnected are very much similar. This is mostly solved by the theory of inflation.
		\item \textbf{The Flatness Problem}: The universe can only have three geometries: closed, open, or flat. There is no reason to expect the universe to be flat, and yet it appears to be flat to a very high precision. This, too, is solved by the inflation theory, which says that the universe will have expanded so greatly that any curvature is undetectable.
		\item \textbf{The Baryon Asymmetry Problem}: Why do we primarily have matter and very little anti-matter?
		\item \textbf{The Primordial Fluctuations Problem}: What caused the primordial fluctuations that gave rise to the first galaxies?
		\item \textbf{The Fine-Tuning Problem}: The energy densities of matter, radiation, curvature, and dark energy seem to be uniquely balanced to produce the flat universe that we observe. This is more of a philosophical problem than a scientific problem (think anthropic principle).
		\item \textbf{What is the Universe Made Of?} Two huge components of the universe are dark energy and dark matter. We know next to nothing about the nature of these mysterious forms of energy and cannot reproduce their effects in the laboratory.
	\end{itemize}
	There are also some interesting epistemological issues that arise from the fact that cosmology is not a classical scientific problem. We only have \emph{one} universe with \emph{one} specific location within that universe, and we can only observe from \emph{one} particular time in the evolution of this universe. We are thus very limited in our view of the universe, and we require assumptions to simplify our observations.\\
	
	\n One of those assumptions is the so-called \textbf{Cosmological Principle}, which postulates that our point of view is not special in any way. Earth is not in any particularly special point and we aren't in a particularly special time. This assumes that the laws of physics are independent of space and time. This is also a natural outgrowth of Ockham's razor (explanations should be as simple as possible). On large enough length scales, these assumptions are quite accurate, but we also see that on small enough scales, there are ``special'' places. For example, we are in a galaxy, but the majority of the universe is not galactic.
	% subsection the_long_view (end)	
	\subsection{The Game Plan} % (fold)
	\label{sub:the_game_plan}
		The course has a five-part plan:
		\begin{itemize}
			\item \textbf{Part 0}: Basic Phenomenology (L2-4)
			\item \textbf{Part I}: The (Smooth) Average Universe (L5-10)
			\item \textbf{Part II}: The Growth of Fluctuations (L11-L15)
			\item \textbf{Part III}: Very Early Universe (L20)
			\item \textbf{Part IV}: Class Presentations
		\end{itemize}
		To cover this material, we must introduce some particular units and concepts useful to cosmologists:
		\begin{itemize}
			\item \textbf{Parsec} (pc): The distance that gives a parallax of 1 arcsecond $\approx 3.08\times 10^{16}\,\mathrm{m}$
			\item \textbf{Solar Mass} ($M_\odot$): $\approx 2\times10^{30}\,\mathrm{kg} = 2\times 10^{33}\ \mathrm{g}$
			\item \textbf{Solar Luminosity} ($L_\odot$): $\approx 3.8\times 10^{26}\ \mathrm{W} = 3.8\times 10^{33}\ \mathrm{erg/s}$
			\item \textbf{Redshift} ($z$): $\equiv \lambda/\lambda_0-1$
			\item \textbf{Apparent Magnitude} ($m$): A measure of flux
			\begin{itemize}
				\item $m=-2.5\log F/F_0$ for some zero-point flux, $F_0$ (usually that of Vega)
				\item Letters indicate a particular band (filter) a magnitude is measured in (classic Johnson UBV filters, for example). There are \emph{many} different bands in use. Ex. $m_U$ or simply $U$ would be the $U$-band magnitude, or $m_U=-2.5 \log F_U/F_{0,U}$.
			\end{itemize}
			\item \textbf{Absolute Magnitude} ($M$) A measure of luminosity, defined as what the apparent magnitude of an object \emph{would} be if it were located at a distance of 10 pc.
			\begin{itemize}
				\item For the sun, $M_V = -4.83$ (the absolute magnitude in the $V$-band)
				\item For the Andromeda galaxy, $M_V\sim -20$
			\end{itemize}
		\end{itemize}
	% subsection the_game_plan (end)

% section introduction (end)	

\section{Phenomenology} % (fold)
\label{sec:phenomenology}
	One of the simplest indicators that our universe is not both infinite in extent and time (eternal and infinite) is \textbf{Olbers' Paradox}. This paradox states that if the universe were infinite and eternal, there should be a more or less uniform distribution of stars. Though the intensity of the stars' light would decrease by $1/r^2$, the number of emitters present also \emph{increases} by a factor of $r^2$, so the entire night sky should be as bright as the sun. Any light that runs into gas or something else would always be reprocessed, possibly at another wavelength, but it would still get to us. The BBT solves this paradox by limiting the \emph{age} of the universe. When looking further away, we are looking back in time, eventually reaching a point where stars did not exist yet, truncating the infinite star problem.\\
	
	\n While we can look back in time by looking further away, we unfortunately cannot look at the same place and see multiple times. Instead, we have to make theories about how parts of the universe at certain times evolve to other parts of the universe at later time.\\
	
	\n Another, more recent, observation that is indicative of the Big Bang is Hubble's law. Hubble looked at distant galaxies using Cepheid variables to determine their distance. He took spectra of these galaxies and noted that the spectral lines were nearly always shifted to the red. When he plotted this redshift against the distance, he found a linear relation between distance and velocity, namely
	\begin{equation}
		\label{eq:1} v = H_0 d
	\end{equation}
	where $v$ is the ``velocity'' (though the objects are really at rest\ldots more on this later), $H_0$ is the so-called \textbf{Hubble Constant} (which is not a real constant), and $d$ is the distance to the galaxy.\\
	
	\n A still more recent observation that supports the BBT is the observation of the \textbf{Cosmic Microwave Background}. When observing the universe in the microwave regime, and after subtracting out motion due to peculiar velocities, we see a nearly-perfect blackbody at $T=2.725\pm 0.001\ \mathrm{K}$. There are under-densities and over-densities that eventually give way to galaxies.\\
	
	\n Another interesting property of the universe that begs for understanding is the large-scale structure (LSS) of the universe. We see that galaxies are not uniformly distributed at random, at least on large scales. Rather, the universe is organized into filaments and walls of galaxies (so-called superclusters) and large voids that are under-dense in matter. This is a direct result of the action of heavy dark matter particles and the remnants of the fluctuations in the CMB.\\
	
	\n The basic building blocks in cosmology are galaxies rather than stars. A \textbf{galaxy} is a self-gravitating set of stars, gas, and dark matter. Their typical length scale is a kiloparsec for the baryonic matter and hundreds of kiloparsecs for the dark matter halo, a region with few baryons but relatively high dark matter density. In fact, most of the mass is contained in the dark matter halo, usually around $10^{7}$ to $10^{13}\,M_\odot$. The upper limit to the mass of galaxies is set by the dynamics of the collapse of structures, but the lower limit is a bit of a mystery that may have something to do with the physics of dark matter. The mass contained in stars is at most only a few percent, and the majority of the baryons are in the cold and hot gas known as the \textbf{interstellar medium}. Most galaxies are known to have many satellite and dark subhalos. \\
	
	\n Galaxies can be classified by their morphologies and are often organized by Hubble's tuning fork diagram with elliptical galaxies on the ``handle'' and normal and barred spiral galaxies on the ``tines''. The older elliptical galaxies typically showcase very little to no star formation and thus are red and ``dead'' (since blue stars are typically young). They are typically the largest galaxies with masses up to $10^{12}\,M_\odot$ and feature a hot, X-ray emitting halo. They are often found at the center of groups and clusters in highly clustered formations. With no clear axis of rotation, they are supported by pressure (rather than rotation) and their surface brightness can be described by De Vaucouleurs' law. There are also small elliptical galaxies, down to dwarf sizes that are typically younger and feature stronger rotational support and Seric brightness profiles.\\
	
	\n Spiral galaxies like the Milky Way and Andromeda, on the other hand, have younger stellar populations and thus appear bluer. They are rotationally supported and are rich in cold gas. The spiral ``arms'' are not really entities in and of themselves, but more so moving density waves. There are two main baryonic components to a spiral galaxy: its central bulge and the disk.\\
	
	\n A larger ``unit'' of cosmology is a galaxy cluster. \textbf{Galaxy Clusters} are massive systems, typically with $M> 10^{14}\,M_\odot$. They are often rich in very hot gas (with $kT\sim \mathrm{keV}$ and above), resulting in free-free emission in the X-ray. The gas in these clusters is largely believed to be pressure supported. These clusters are useful for many reasons, including their use as lenses for gravitational lensing and for probing the nature of the universe through their part in the Sunyaev-Zeldovich Effect, where high energy electrons in the cluster give energy to incoming CMB photons.
% section phenomenology (end)

% Monday, January 14, 2012

\section{Geometry in Cosmology} % (fold)
\label{sec:geometry_in_cosmology}
	\emph{Monday, January 14, 2012}\\

	\n We are lucky to be able to define a \textbf{cosmic time}, $t$ that all observers in the universe can supposedly agree on. We are able to define a \textbf{metric} that defines how distance is measured in the universe. In general, we can define many different metrics, but for a curved universe that is assumed to be homogeneous and isotropic, there are really only three options. There is the flat metric (Euclidean), the open metric (hyperbolic), and the closed metric (spherical). The non-flat geometries present some strange properties that we are not used to in everyday experiences. For instance, a circle about the North pole of a sphere will have a circumference smaller than $2\pi r$, where $r$ is the distance from the North pole to the circle, measured along the surface. Additionally, objects on the surface of a sphere appear to get first smaller as they travel away and then, once they pass the equator (when the observer is on a pole), they appear to get \emph{larger} again.\\
	
	\n In two dimensions, we can write the line element in Euclidean (flat) space in Cartesian or spherical coordinates as
	\begin{equation}
		\label{eq:geo:1}
		ds^2 = dx^2+ dy^2 = dr^2 + \Omega^2\,d\theta^2
	\end{equation}
	Though these metrics may appear different, they are really the same, just with a change of coordinates. In fact, a result of differential geometry is that no two physically different metrics can be made to look alike with coordinate changes. On the surface of a sphere, though, the metric must change. There is, after all, a maximum distance between two points now. 
	\begin{equation}
		\label{eq:geo:2} ds^2 = R_c^2\,d\theta^2 + R_c^2\sin^2\theta\,d\phi^2 = R_c^2\left(d\theta^2 + \sin^2\theta\,d\phi^2\right)
	\end{equation}
	Note that $\theta$ here is measured from the North pole, but the position of that pole is really arbitrary, so we are free to place it wherever we like, so long as we are consistent with the following calculations. Here $R_c$ is the radius of curvature. If there surface truly is the surface of a sphere in 3-space, this would be the radius of that sphere, though we need not require our two-dimensional space to be embedded in a three-dimensional space. An equivalent expression of the metric is
	\begin{equation}
		\label{eq:geo:3} ds^2 = dr^2 + R_c^2\sin^2\left(\frac{r}{R_c}\right)\,d\phi^2
	\end{equation}
	where $r=R_c\theta$. To be complete the corresponding metric for an negative (hyperbolic) curvature
	\begin{equation}
		\label{eq:geo:4} ds^2 = dr^2 + R_c^2\sinh^2\left(\frac{r}{R_c}\right)\,d\phi^2
	\end{equation}
	(No proof given because\ldots gross.)\\
	
	\n In three dimensions, the Euclidean metric generalizes in an obvious way, but for the spherical universe, we get
	\begin{equation}
		\label{eq:geo:5} ds^2 = dr^2 + R_c^2\sin^2\left(\frac{r}{R_c}\right)\left[d\theta^2 + \sin^2\theta\,d\phi^2\right]
	\end{equation}
	
	\n If we define
	\begin{equation}
		\label{eq:geo:6} x = \left\{\begin{matrix}
			R_c\sin(r/R_c) & \mathrm{Sphere}\\
			r & \mathrm{Flat}\\
			R_c\sinh(r/R_c) & \mathrm{Hyperbolic}
		\end{matrix}\right.
	\end{equation}
	Then the generalized metric is
	\begin{equation}
		\label{eq:geo:7} ds^2 = \frac{dx^2}{1-\kappa x^2} + x^2\left[d\theta^2+\sin^2\theta\,d\phi^2\right]
	\end{equation}
	where $\kappa=1$ for a closed (spherical) universe, $\kappa=0$ for a flat universe, or $\kappa=-1$ for an open universe. At this point, we have only considered static (time-independent) metrics. The obvious starting point for adding time-dependence is the Minkowski metric from special relativity:
	\begin{equation}
		\label{eq:geo:8} ds^2 = -dt^2 + dx^2 + dy^2 + dz^2
	\end{equation}
	The resulting, generalized metric is the \textbf{Robertson-Walker} metric:
	\begin{equation}
		\label{eq:geo:9} ds^2 = dt^2 - \frac{a^2(t)}{c^2}\left[dr^2 + R^2\sin^2\left(\frac{r}{R_c}\right)\left(d\theta^2+\sin^2\theta\,d\phi^2\right)\right]
	\end{equation}
	for closed space, or, more generally,
	\begin{equation}
		\label{eq:geo:10} ds^2 = dt^2-\frac{a^2(t)}{c^2}d\tilde{s}^2
	\end{equation}
	where $d\tilde{s}^2$ is the metric for the static geometry given in \eqref{eq:geo:7}. The function $a(t)$ controls the expansion or contraction of the manifold, and is called the \textbf{scale factor}. Understanding the evolution of $a(t)$ is crucial to our understanding of the history of the universe. Without knowing $a(t)$ a priori, we can still make a lot of statements about the universe's evolution for any generalized $a(t)$.\\
	
	\n As one concrete example, consider the motion of photons along the $r$-direction in flat space. Since photons travel along null geodesics ($ds^2=0$), we have
	\begin{equation}
		\label{eq:geo:11} 0=dt^2 - \frac{a^2(t)}{c^2}dr^2 \qquad \Rightarrow \qquad \frac{c\,dt}{a} = dr
	\end{equation}
	Suppose two successive wave crests of the photons were emitted at time $t_0$, separated by an interval $\Delta t_0$. They arrive to us at time $t_1$ separated by an interval $\Delta t_1$. Simply using \eqref{eq:geo:11}, we find
	\begin{equation}
		\label{eq:geo:12} \int_{t_1}^{t_0}\frac{c\,dt}{a(t)} = -\int_r^0dr =\int_{t_1+\Delta t_1}^{t_0+\Delta t_0}\frac{c\,dt}{a(t)} = \int_{t_1}^{t_0}\frac{c\,dt}{a(t)} + \frac{c\Delta t_0}{a(t_0)} - \frac{c\Delta t_1}{a(t_1)}
	\end{equation}
	Which tells us that
	\begin{equation}
		\label{eq:geo:13} 0 = \frac{c\Delta t_0}{a(t_0)} - \frac{c\Delta t_1}{a(t_1)} \qquad \Rightarrow \qquad \frac{\Delta t_0}{\Delta t_1} = \frac{a(t_0)}{a(t_1)} = \frac{1}{a(t_1)}
	\end{equation}
	where we've used the convention that $a(t_0)$ ($a$ now) is unity. The result here is that photons in an expanding universe \emph{lose energy}. This ratio is also related to the redshift, so we often define the redshift, $z$, via
	\begin{equation}
		\label{eq:geo:14} 1+z = \frac{1}{a(t)}
	\end{equation}
	This is actually an easily observed phenomenon for any thing sufficiently far away, though we do not regard these faraway objects as actually \emph{moving} per se. Rather, the space between objects is increasing, causing this observed redshift.
	
	\subsection{Hubble's Law} % (fold)
	\label{sub:hubble_s_law}
	Our earlier result tells us that
	\begin{equation}
		\label{eq:hubble:1} \int_{t_1}{t_0} \frac{c}{a(t)}dt = r
	\end{equation}
	If we consider small enough time intervals ($t_1\approx t_0$), the integrand is essentially a constant, and we get
	\begin{equation}
		\label{eq:hubble:2} r = \frac{c(t_0-t_1)}{a(t_0)}
	\end{equation}
	Now if we revisit our friend the redshift and do a taylor expansion around the present time, we get
	\begin{equation}
		\label{eq:hubble:3} z = \frac{a(t_0)}{a(t_1)}-1 = \frac{a(t_0)}{a(t_0)+(t_1-t_0)a'(t_0)}-1 = \frac{1}{1-(t_0-t_1)\frac{\dot{a}(t_0)}{a(t_0)}}-1\approx (t_0-t_1)\frac{\dot{a}(t_0)}{a(t_0)} = \frac{r}{c}\dot{a}(t_0)
	\end{equation}
	where in the last step we have used \eqref{eq:hubble:2}. So we have recovered the famous law of Hubble,
	\begin{equation}
		\label{eq:hubble:4} v\approx H_0 d
	\end{equation}
	where $H_0=\dot{a}(t_0)\approx 70\ \mathrm{km/s/Mpc}$. This required nothing other than general geometric arguments.\\
	
	\n A few notes on notation: often in the literature, $h$ will be used in place of $H_0$, where $h= H/100\ \mathrm{km/s/Mpc}$. Others still will use $h_{70} = H_0 / 70\ \mathrm{km/s/Mpc}$.
	% subsection hubble_s_law (end)
	\subsection{Cosmography} % (fold)
	\label{sub:cosmography}
		To measure distances in the universe, we employ the tools of Cosmography. There are many distances of interest. In fact, there are many differences to one particular location! We have the \textbf{angular diameter distance}, defined by
		\begin{equation}
			\label{eq:distances:1} D_A = \frac{d}{\theta}
		\end{equation}
		where $d$ is the known diameter of the object and $\theta$ is the angular diameter as measured from Earth. Another distance is the \textbf{luminosity distance}, defined by
		\begin{equation}
			\label{eq:distances:2} D_\mathrm{L}^2 = \frac{L}{4\pi F}
		\end{equation}
		This is used when comparing the observed flux from an object of known luminosity to get a distance. Note that these two distance are not, in general, equal. There is a factor of $(1+z)^2$ between the two. For a spherical geometry, where $R$ is the co-moving coordinate of an object (i.e., $r$ is invariant in time), these two distances are related via
		\begin{align}
			\label{eq:eq:distances:3} D_A &= \frac{R_c \sin(r/R_c)}{1+z}\\
			\label{eq:eq:distances:4} D_L &= D_A(1+z)^2
		\end{align}
		To move these results to flat or open geometry, the $\sin$ business would change accordingly. A detailed description of these discrepancies between the measurements of distance are given in Longair, but the short version of it is that in addition to the ``distance'' part that redshift gives to the distance, the redshift of the photons also robs the photons of their former count rate (by a factor of $1+z$) as well as their energy (by another factor of $1+z$).\\
	
		\n Another question one might ask is how much volume is contained between two shells at redshifts $z_1$ and $z_2$? This question is very important when making estimates of how many objects one might expect to see during survey (see exercises).\\
	
		\n The \textbf{lookback time} is an important quantity that tells us how far back in time we are looking at a particular object. Often we are interested in finding $t(z)$ to relate measured redshifts to lookback times. To do this, we need to use the \textbf{Hubble Parameter}:
		\begin{equation}
			\label{eq:distances:5} H(t) = \frac{\dot{a}(t)}{a(t)}
		\end{equation}
		Note that the Hubble constant is just the current value of the Hubble parameter. The calculation that needs to be done to find the lookback time is then
		\begin{equation}
			\label{eq:distances:6} t(z) = \int_0^z \frac{dz}{H(z)}\frac{1}{1+z}
		\end{equation}
	
		% Wednesday, January 16, 2013
		\textit{Wednesday, January 16, 2013}\\
	
		\n [MISSING STUFF]\\
	
		\n The lookback time can be expressed as a function of $z$ as
		\begin{equation}
			\label{eq:distances:7} t(z) = \int_0^z\frac{dz'}{H(z')(1+z')}
		\end{equation}
		We can also find the lookback distance as a function of $z$:
		\begin{equation}
			\label{eq:distances:8} r(z) = \int_0^z \frac{c\,dz'}{H(z')} = \int_{t_0}^\infty \frac{c\,dt}{a'(t)}
		\end{equation}
		If we extend $z\to\infty$ we find the age of the universe and the horizon.

	% subsection cosmography (end)
% section geometry_in_cosmology (end)
\section{Cosmic Dynamics} % (fold)
\label{sec:cosmic_dynamics}
	\subsection{Friedmann's Equation (Classical Derivation)} % (fold)
	\label{sub:friedmann_s_equation_classical_derivation_}
		Consider a sphere within a homogeneous and isotropic universe. We wish to find the equation of motion of the particles along the surface of this sphere. For convenience, consider the initial radius to be unity so that we can write the radius at any time as $a(t)$. The acceleration due to the gravitational pull would be
		\begin{equation}
			\label{eq:dynamics:1} \ddot{a}(t) = -\frac{GM}{a^2}=-\frac{4\pi}{3}G\rho a
		\end{equation}
		where in the second equality we have used the fact that density is constant. If we multiply both sides by $\dot{a}$, we get
		\begin{equation}
			\label{eq:dynamics:2} \ddot{a}(t)\dot{a}(t) = -\frac{4\pi}{3}G\rho a \dot{a}
		\end{equation}
		Integrating this, we find
		\begin{equation}
			\label{eq:dynamics:3} \frac{1}{2}\dot{a}^2=\frac{4\pi}{3}G\rho_0\frac{a_0^3}{a}+\frac{c}{2}
		\end{equation}
		If we define the \textbf{critical density} of the universe at the current time as
		\begin{equation}
			\label{eq:dynamics:4} \Omega_0=\frac{8\pi G \rho_0}{3H_0^2}
		\end{equation}
		and note that at the present time, the equation reads
		\begin{equation}
			\label{eq:dynamics:5} \frac{1}{2}\frac{\dot{a}^2(t_0)}{a_0^2} = \frac{4\pi}{3}G\rho_0\frac{a_0}{a_0} + \frac{c}{a_0^2}
		\end{equation}
		and finally defining $\dot{a}(t_0)/a(t_0)=H_0$, we may write
		\begin{equation}
			\label{eq:dynamics:6} 1 = \Omega_0 + \frac{c}{a_0^2H_0^2}
		\end{equation}
		This allows us to rewrite \eqref{eq:dynamics:3} as the ``fake'' \textbf{Friedmann's Equation}
		\begin{equation}
			\label{eq:dynamics:7} \left(\frac{\dot{a}}{a}\right)^2 = \Omega_0 H_0^2\left(\frac{a_0}{a}\right)^3+(1-\Omega_0)\left(\frac{a_0}{a}\right)^2
		\end{equation}
		This equation reflects three possibilities for the fate of the sphere. First, if the density is below $\Omega_0$, the sphere will expand forever and reach some asymptotic expansion velocity. If the density is exactly the critical density, the sphere will expand forever, but will asymptotically approach zero expansion velocity. Finally, if the sphere is denser than $\Omega_0$, the sphere will eventually collapse back on itself.\\
		
		\n To do this ``right'', we need the full machinery of Einstein's equation:
		\begin{equation}
			\label{eq:dynamics:8} R_{\mu\nu}-\frac{1}{2}g_{\mu\nu}R = \frac{8\pi G}{c^2}T_{\mu\nu}
		\end{equation}
		Where $R_{\mu\nu}$ is the Ricci Tensor, $R=R^\mu_{\phantom{\mu}\mu}$ is the Ricci scalar, and $T_{\mu\nu}$ is the stress-energy tensor of the universe, often taken to be that of a perfect fluid:
		\begin{equation}
			\label{eq:dynamics:9}
			T_{\mu\nu} = \begin{pmatrix}
			\rho & 0 & 0 & 0\\
			0 & p & 0 & 0\\
			0 & 0 & p & 0\\
			0 & 0 & 0 & p \end{pmatrix}
		\end{equation}
		where $P$ is the pressure and $\rho$ is the energy density. We won't go through the details here, but the corresponding version of Friedmann's equation as developed from general relativity is
		\begin{equation}
			\label{eq:dynamics:10} \left(\frac{\dot{a}}{a}\right)^2 = \frac{8\pi g\rho}{3}-\frac{\kappa c^2}{a^2 + \frac{1}{3}\Lambda}
		\end{equation}
		where $\kappa$ is the curvature ($-1$ for open, $0$ for flat, $+1$ for closed) term and $\Lambda$ is the cosmological constant (if it indeed exists).\\
		
		\n The second derivative equation gives
		\begin{equation}
			\label{eq:dynamics:11} \ddot{a} = -\frac{4\pi G}{3}a\left(\rho + \frac{3P}{c^2}\right)+\frac{1}{3}\Lambda a
		\end{equation}
		where $P$ is the pressure. Combining these results gives the ``better'' Friedmann's equation:
		\begin{equation}
			\label{eq:dynamics:12}\boxed{\left(\frac{\dot{a}}{a}\right)^2 = H_0^2\left[\Omega_0\left(1+z\right)^3+(1-\Omega_0-\Omega_\Lambda)(1+z)^2 + \Omega_\Lambda\right]}
		\end{equation}
		We've technically left out some terms with $\Omega_\gamma(1+z)^4$, which represents the energy density due to radiation, but in our current understanding, that term is negligible. Also, sometimes we see another $\Omega$ defined via $\Omega_\kappa = 1-\Omega_0-\Omega_\Lambda$ to be the energy density provided by curvature (whatever that means). If this is positive, we have open curvature. If it is zero, we have flat curvature, and if it is negative, we have closed curvature. Note that aside from the terms provided by $\Omega_\Lambda$ (and optionally $\Omega_\gamma$), this form of Friedmann's equation matches exactly with \eqref{eq:dynamics:7}.\\
		
		\n We should also consider the work done by an expanding universe. From thermodynamics, we have the classic $dU = -p\,dV$ relation, where for our purposes, $V=a^3$. Often we wish to express the pressure as some multiple of the energy density via an \textbf{equation of state}, namely
		\begin{equation}
			\label{eq:dynamics:13} \frac{p}{c^2} = w\rho
		\end{equation}
		where $w$ is the interesting parameter to be determined. Using this substitution in \eqref{eq:dynamics:11} gives
		\begin{equation}
			\label{eq:dynamics:14} \ddot{a} = -\frac{4\pi G}{3} a\rho(1+3w)+\frac{1}{3}\Lambda a
		\end{equation}
		Which then gives the differential relation
		\begin{equation}
			\label{eq:dynamics:15} d\rho\,a^3 c^2 + da\,3a^2\rho c^2 = -p 3a^2\,da
		\end{equation}
		and so the density (of any kind) follows
		\begin{equation}
			\label{eq:dynamics:16} \rho \propto (1+z)^{3+3w}
		\end{equation}
		We can write the full-blown form of Friedmann's equation, valid at all times as
		\begin{equation}
			\label{eq:dynamics:17} \boxed{H^2(z) = H_0^2\left[\Omega_\gamma(z+z)^4 + \Omega_0(1+z)^3 + \Omega_\kappa(1+z)^2 + \Omega_{\mathrm{de}}(1+z)^{3+3w}+\Omega_\Lambda\right]}
		\end{equation}
		This particular form allows for both a cosmological constant \emph{and} dark energy. Typically we just assume that $\Omega_{\mathrm{de}}$ is the cosomological constant (i.e., $w=-1$) and we drop the additional term. However, this form is strictly more general.
	% subsection friedmann_s_equation_classical_derivation_ (end)
	\subsection{Using Friedmann's Equation} % (fold)
	\label{sub:using_friedmann_s_equation}
		We can use Friedmann's equation to make many useful computations. For instance, the cosmic distance in a universe with only matter (all other $\Omega$'s vanish)
		\begin{equation}
			\label{eq:dynamics:18} r = \int_0^z \frac{c\,dz'}{H(z')} = \frac{2c}{H_0\Omega_0^2(1+z)}\left\{\Omega_0z+(\Omega_0-1)\left[(\Omega_0z+1)^2-1\right]\right\}
		\end{equation}
		If we expand this to first order in $z$, we recover Hubble's Law: $D\approx zc/H_0$. Now if we assume $\Omega_0=1$, which is the Einstein-de Sitter case, this result simplifies to
		\begin{equation}
			\label{eq:dynamics:19} D = \frac{2c}{H_0}\left[2-\frac{1}{\sqrt{1+z}}\right]
		\end{equation}
		\subsubsection{The Einstein-de Sitter Case} % (fold)
		\label{ssub:the_einstein_de_sitter_case}
			In the Einstein-de Sitter universe, Friedmann's equation simplifies dramatically to
			\begin{equation}
				\label{eq:dynamics:20} H^2(z) = H_0^2\Omega_0(1+z)^3
			\end{equation}
			or simply
			\begin{equation}
				\label{eq:dynamics:21} H(z) = H_0\sqrt{\Omega_0}(1+z)^{3/2}
			\end{equation}
			Choosing $a$ over $z$ and $H$ gives us
			\begin{equation}
				\label{eq:dynamics:22} \frac{\dot{a}}{a} = H_0\Omega_0^{1/2}\frac{1}{a^{3/2}}
			\end{equation}
			We can solve for $a(t)$ (which essentially tells us everything) relatively simply:
			\begin{equation}
				\label{eq:dynamics:23} \frac{da}{a}a^{3/2} = a^{1/2}\,da = H_0\Omega_0^{1/2}\,dt
			\end{equation}
			The solution for $a(t)$ is
			\begin{equation}
				\label{eq:dynamics:24} a = \left[\frac{3}{2}H_0 \Omega_0^{1/2}(t-t_0)\right]^{2/3}+1
			\end{equation}
			Solving for the current age of the universe in this universe gives us
			\begin{equation}
				\label{eq:dynamics:25} t_0 = \frac{2}{3}H_0^{-1}
			\end{equation}
			This actually causes problems since we know of objects that are older than this, so we know that we do not live in an Einstein-de Sitter universe.\\
		% subsubsection the_einstein_de_sitter_case (end)
	% subsection using_friedmann_s_equation (end)
% section cosmic_dynamics (end)
\section{Cosmography} % (fold)
\label{sec:cosmography}
\n \textit{Wednesday, January 23, 2013}\\

	\n Much of observational cosmology focuses on finding a few particular numbers. $H_0$, $q_0$ (the deceleration parameter), $t_0$ (the age of the universe), $\Omega_i$ (the density parameters) all are crucial to our understanding of the evolution of the universe, so measuring them accurately is of the utmost importance. 
	\subsection{The Search for the Hubble Constant} % (fold)
	\label{sub:the_search_for_h_0_}
	A decent part of the last century in cosmology has been invested in getting an accurate measurement of the Hubble constant, $H_0$. Originally it was prioritized so that we could determine distance to objects at small redshift with relative accuracy, but more recently we've found other reasons to want to know the value of $H_0$ to within one percent accuracy.\\
	
	\n Now, if we have an accurate measurement of $H_0$, we can constrain values of other cosmological parameters, like $w$, the dark energy equation of state parameter. In the past, these cosmological parameters were dealt with on an individual basis, but modern experiments treat the problem in a multi-dimensional fashion, giving simultaneous ranges for multiple cosmological parameters.\\
	
	\n Over time, the value of $H_0$ has fallen from over $h=6$ (from Hubble's first measurements) in the 1920's down to between $h=0.5$ to $h=1.0$ from about 1960-2000. The varied values during those forty years was likely due to under-estimated error bars, which caused quite a kerfuffel among cosmologists. In the last decade, the measurements are converging towards $h=0.7$ to within about ten percent. A new generation of experiments hopes to get the value to within one percent.
	
	\subsubsection{The Distance Ladder} % (fold)
	\label{ssub:the_distance_ladder}
		Unfortunately, when measuring redshifts of distant galaxies, it is very difficult to separate the effects from cosmic expansion from the doppler shift due to peculiar velocities. To calibrate Hubble's law properly, we need to determine distances through some other means. In determining distances at various length scales around the universe, astronomers make use of the so-called \textbf{distance ladder}, which is a series of methods of determining the distance to an object, with each method reaching further than the last, but leaning on the accuracy of the previous method.\\
		
		\n The ``base'' method is the familiar parallax method for determining the distance to nearby stars. For slightly further objects (the Magellanic clouds, nearby galaxies), we can use Cepheid variable stars to determine a distance from the period luminosity relation (Cepheids pulsate with a frequency that is directly related to their luminosity). Since these can be used as a standard candle, we can ascertain a distance from a flux measurement and the $1/r^2$ law. With a second method of distance determination, we can find what the Hubble flow really is, allowing us to compensate for peculiar velocities. The Key Project aimed to do this and came up with a measurement of $H_0 = 72 \pm 7\ \mathrm{km/s/Mpc}$.
	% subsubsection the_distance_ladder (end)
	\subsubsection{Beyond the Key Project} % (fold)
	\label{ssub:beyond_the_key_project}
		Rather than using Cepheids, newer studies are using type Ia supernovae, bypassing a calibration via the LMC. The idea is that the uncertainty from LMC measurements will be avoided, resulting in a more precise measurement. This process, along with some other breakthroughs allowed Riess et al.~(2011) to reduce the uncertainty down to three percent in the SHOES project.\\
		
		\n Competing work from the Carnegie Hubble Project (CHP) instead looked at the mid-infrared for Cepheids which reduced uncertainty in other areas and came to about the same value of $H_0$ with the same uncertainty.
	% subsubsection beyond_the_key_project (end)
	% subsection the_search_for_h_0_ (end)
	\subsection{More Distant Measurements} % (fold)
	\label{sub:more_distant_measurements}
		To probe for effects apparent at higher redshifts, we need a robust standard candle. Many options were tried, like the brightest galaxy in a cluster or other less successful methods. To date, the best tool is are type Ia supernovae, which are thought to be the thermonuclear detonation of a C-O white dwarf. The actual progenitor of this system is not known, but they seem to have a uniform luminosity at peak luminosity. Actually, the luminosity is not quite standard, but it is calibrated by the width (in time) of the light curve (often referred to as the ``stretch''). In the future, light curves in the IR will be used since they appear to be truly standardized (``stretch''-independent). There are some difficulties to overcome in this. Errors due to interstellar reddening and atmospheric extinction make high-precision photometry very difficult.\\
		
		\n Recent work using Ias as standard candles seem to favor a cosmological constant for dark energy and $\Omega_m\sim 0.27$. However, several challenges still stand in the realm of Type Ia supernova cosmology, including the poorly understood physics behind their creation, selection effects (the brightest events are most likely to be detected, biasing our results), unknown dust contamination, and precise photometric calibration, as mentioned earlier.
	% subsection more_distant_measurements (end)
	\subsection{Cosmic Chronometers} % (fold)
	\label{sub:cosmic_chronometers}
	Aside from computing distances and the Hubble constant, we also can glean some information about the universe if we can find its age. We mentioned earlier that for an Einstein-de Sitter universe, the age is $t_0 = \frac{2}{3}H_0^{-1}$. If we found the age of the universe to be this, it would be one piece of evidence for (or against) a particular cosmological model. Stellar evolution puts a lower limit on the age of the universe since we see globular clusters with stars around 12 Gyrs old. To date, really all we can do is put lower limits on the age of the universe. It's very difficult to estimate the age of very distant objects, especially since galaxies change over time. As such, this is still an emerging subfield in cosmology. More methods are needed to corroborate the measurements made to date.
	% subsection cosmic_chronometers (end)
% section cosmography (end)
\section{Gravitational Lensing} % (fold)
\label{sec:gravitational_lensing}
	% Wednesday, January 30, 2013
	\textit{Wednesday, January 30, 2013}\\
	\subsection{Strong Lensing} % (fold)
	\label{sub:strong_lensing}
	\textbf{Strong Lensing} refers to the effect of extremely massive objects distorting the incoming light from objects behind. Often the ``lenses'' are large clusters of galaxies changing the image of galaxies behind them. The object behind is the source, and we speak of it being located in the \textbf{source plane}. The lensing object then deflects light from the source through a deflection angle. This can cause the perceived angular diameter of the object to change. Essentially the lens acts as a highly nonlinear mapping from $\mathbb{R}^2$ to $\mathbb{R}^2$. We will often refer to the distance from the deflector to the observer as $D_{\mathrm{d}}$, the distance from the deflector to the source as $D_{\mathrm{ds}}$, and the distance from the source to the observer as $D_{\mathrm{s}}$.\\
	
	\n The lensing causes a change in optical path length, but this also affects the arrival time of light from the source. The effect can be expressed mathematically via
	\begin{equation}
		\label{eq:strong_lensing:1} t(\vec{\theta}) = \frac{1+z_d}{c}\frac{D_{\mathrm{d}}D_{\mathrm{s}}}{D_{\mathrm{ds}}}\left[\frac{1}{2}(\vec{\theta}-\vec{\beta})^2-\psi(\vec{\theta})\right]
	\end{equation}
	Where $\beta$ is the angle between the source and the deflector with respect to the source plane and $\theta$ is the observed angular diameter of the lensed source. The factor of $(\vec{\theta}-\vec{\beta})^2$ is due to the geometry and is the geometric time delay, but the $\psi(\vec{\theta})$ is the gravitational effect, essentially accounting for the fact that the photons must travel along longer geodesics in deeper gravitational wells. There are many useful equations that can be derived from this phenomenon that allows us to learn about cosmic distances, but I do not list them here. They are well documented in the lecture slides and the reference paper.\\
	
	\n There are many reasons to study strong lensing. When observing a lensing event, we can very accurately measure the mass enclosed within the Einstein radius, the projected orientation of the mass, the projected ellipticity of the mass, and sometimes the derivative of the enclosed mass. The lensing matter need not be visible, so this is great for probing dark matter distributions. The strengths of strong lensing as a method are that the mass is independent of a dynamic state and that we can measure the total mass (regardless of the nature of that mass). Weaknesses lie in the susceptibility to projection effects and that we can \emph{only} measure total mass.\\
	
	\n Most relevant for our purposes is using strong lensing to do cosmography with arrival time delays. Since the time delay is proportional to the Fermat distance, $D_{\mathrm{d}}D_{\mathrm{s}}/D_{\mathrm{ds}}$, we gain information about the Hubble constant and some function of the cosmological parameters,
	\begin{equation}
		\label{eq:strong_lensing:2} \Delta t \propto D_{\mathrm{\Delta t}}(z_s,z_d)\propto H_0^{-1} f(\Omega_m,w,\ldots)
	\end{equation}
	After measuring the time delay and solving for the gravitational potential, in theory this can translate into the desired cosmological parameters.

	% subsection strong_lensing (end)

% section gravitational_lensing (end)
\section{Thermal History of the Universe} % (fold)
\label{sec:thermal_history_of_the_universe}
For the nonrelativistic case ($kT\gg mc^2$), a Maxwell-Boltzmann distribution of energies gives a number density 
\begin{equation}
	\label{eq:thermal:1} n = \frac{g}{h^3}\int_0^\infty f(\mathbf{p})\,d^3p = g\left(\frac{2\pi mkT}{h^2}\right)^{\frac{3}{2}} e^{-\frac{mc^2-\mu}{kT}}
\end{equation}
In the relativistic case, however, where $kT\gg mc^2$ and $kT\gg\mu$, things become simpler:
\begin{equation}
	\label{eq:thermal:2} n_b = \frac{g\zeta(3)}{\pi^2} \left(\frac{2\pi k T}{hc}\right)^3
\end{equation}
and
\begin{equation}
	\label{eq:thermal:3} n_f = \frac{3}{4}\frac{g\zeta(3)}{\pi^2} \left(\frac{2\pi k T}{hc}\right)^3
\end{equation}
for bosons and fermions, respectively. For the current CMB with $T\approx 2.7\ \mathrm{K}$, this corresponds to a number density of around $4\times 10^8\ \mathrm{m^{-3}}$. Compare that to the baryonic number density, which is about $1\ \mathrm{m^{-3}}$, so there are about a billion photons per baryon in the universe. The corresponding amount of energy is roughly equivalent to what would be gained by fusing all hydrogen in the universe into helium.\\

\n Since the radiation energy density scales as $(1+z)^4$ and matter energy density scales only as $(1+z)^3$, there was a time when radiation dominated the universe. In fact, aside from a few awkward transitions, the universe has always been dominated by a single component. We happen to live in the awkward transition from matter to dark energy right now. As such, many calculations for the evolution of the scale factor become trivial when in the regime of a single-component universe.

\subsection{Era of Recombination} % (fold)
\label{sub:era_of_recombination}
	There came a time when the CMB became cool enough to allow electrons to bind to ions and form neutral atoms. For some reason, this is called \textbf{Recombination}. We would expect this to occur when $kT_{\mathrm{CMB}}\sim 13.6\,\mathrm{eV}$. To do this correctly, we need to use the Saha equation, which gives us the number densities of species at various stages of ionization:
	\begin{equation}
		\label{eq:recomb:1} n_i = g_i \left(\frac{2\pi m_i kT}{h^2}\right)^{3/2}e^{-\frac{\mu -m_i c^2}{kT}}
	\end{equation}
	whilst requiring conservation of chemical potential:
	\begin{equation}
		\label{eq:recomb:2} \mu(e^-) + \mu(p^+) = \mu(\mathrm{H})
	\end{equation}
	Manipulating the three corresponding version of \eqref{eq:recomb:1} and using \eqref{eq:recomb:2} gives us
	\begin{equation}
		\label{eq:recomb:3} \frac{n_{\mathrm{H}}}{n_{e}n_p} = \frac{g_\mathrm{H}}{g_eg_p} \left(\frac{h^2}{2\pi m_ekT}\right)^{3/2} e^{-\frac{13.6\,\mathrm{eV}}{kT}}
	\end{equation}
	If we define $x=n_p/n_{\mathrm{\rm B}} = \frac{n_e}{n_{\rm B}}$ where ``B'' stands for baryons (protons or hydrogen atoms), we can re-express \eqref{eq:recomb:3} in terms of this ionization fraction:
	\begin{equation}
		\label{eq:recomb:4} \frac{1-x}{x^2n_{\rm B}} = \left(\frac{h^2}{2\pi m_e kT}\right)^{3/2}e^{-\frac{13.6\ \mathrm{eV}}{kT}}
	\end{equation}
	now if $\eta$ is the ratio of photon number density and baryon number density, we can rewrite this as
	\begin{equation}
		\label{eq:recomb:5} \frac{1-x}{x^2} = \eta n_\gamma\left(\frac{h^2}{2\pi m_e kT}\right)^{3/2} e^{-\frac{-13.6\,\mathrm{eV}}{kT}} = \eta\frac{\zeta(3)}{\pi^2}\left(\frac{2\pi k T}{hc}\right)^3 \left( \frac{h^2}{2\pi m_e kT}\right)^{3/2} e^{-\frac{13.6\,\mathrm{eV}}{kT}}
	\end{equation}
	where in the last form, we used \eqref{eq:thermal:2}. This is the Saha equation, albeit simplified since we neglect the effects of helium and other interfering influences in the universe. When $x$ is large, there are many free electrons, which cause Thomson scattering to affect the paths of photons. Because of this, we are unable to see beyond this ``surface of last scattering'' where the universe itself is effectively opaque. This occurred at about $z\sim 1000$, when matter still dominated the universe. We can do some ugly mathematics to calculate the optical depth due to this thomson scattering as a function of redshift:
	\begin{equation}
		\label{eq:recomb:6} \tau_T = 0.035\frac{\Omega_b}{\Omega_m^{1/2}}hz^{3/2}\qquad [z\gg 1;\ x=1]
	\end{equation}
	\subsection{Radiation Dominated Era} % (fold)
	\label{sub:radiation_dominated_era}
	At first, baryons and radiation were coupled through Thomason scattering, so photons could not travel freely about the universe. After recombination, they decouple, and each component expanded adiabatically with temperature scaling via $T\sim 1/a$ for photons and $T\sim 1/a^2$ for baryons. The exchange of energy from photons to electrons via scattering gives us a temperature change rae of
	\begin{equation}
		\label{eq:radiation:1} \frac{dT_e}{dt} = \frac{4}{3}\sigma_T\epsilon_r\left(\frac{T_r-T_e}{m_ec}\right)
	\end{equation}
	And since the heat capacity of the CMB is much higher, changes in the electron temperature occur on a timescale much shorter than the age of the universe:
	\begin{equation}
		\label{eq:radiation:2} \tau = \frac{T_e}{dT_e/dt} = 7.4\times 10^{19}z^{-4}\ \mathrm{s}
	\end{equation}
	A similar process occurs for the hydrogen atoms later in time, but since the number of free electrons is decreasing, this effect is depressed, and we get effective decoupling by $z\sim 150$. After this time, photons and matter essentially stop communicating with each other.
	% subsection radiation_dominated_era (end)
% subsection era_of_recombination (end)
% section thermal_history_of_the_universe (end)
\end{document}

